{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "Softmax Classifier using MNIST numbers dataset<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import torch\n", "import torch.nn as nn\n", "import torchvision.transforms as transforms\n", "import torchvision.datasets as dsets\n", "from torch.utils.data import DataLoader\n", "import matplotlib.pyplot as plt\n", "import numpy as np"]}, {"cell_type": "markdown", "metadata": {}, "source": ["efine a plotting function to plot parameters"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def PlotParameters(model): \n", "    W = model.state_dict()['linear.weight'].data\n", "    w_min = W.min().item()\n", "    w_max = W.max().item()\n", "    fig, axes = plt.subplots(2, 5)\n", "    fig.subplots_adjust(hspace=0.01, wspace=0.1)\n", "    for i, ax in enumerate(axes.flat):\n", "        if i < 10:\n", "            \n", "            # Set the label for the sub-plot.\n", "            ax.set_xlabel(\"class: {0}\".format(i))\n\n", "            # Plot the image.\n", "            ax.imshow(W[i, :].view(28, 28), vmin=w_min, vmax=w_max, cmap='seismic')\n", "            ax.set_xticks([])\n", "            ax.set_yticks([])\n\n", "        # Ensure the plot is shown correctly with multiple plots\n", "        # in a single Notebook cell.\n", "    plt.show()\n", "    \n", "def show_data(data_sample):\n", "    plt.imshow(data_sample[0].numpy().reshape(28, 28), cmap='gray') #Showing image 28x28 in gray scale\n", "    plt.title('y = ' + str(data_sample[1].item())) #Showing title as label corresponding to image"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ets Create some data (training set from mnist)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_dataset = dsets.MNIST(root='./data', train = True, download = True, transform = transforms.ToTensor())\n", "print(\"The Training dataset:\\n\", train_dataset)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["reate validation set"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["val_dataset = dsets.MNIST(root = './data', train = False, download = True, transform = transforms.ToTensor())\n", "print(\"The Validation dataset:\\n\", val_dataset)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["rint datatype"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"Type of data element: \", train_dataset[0][1].type())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["lotting image samples"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"The image: \", show_data(train_dataset[3]))\n", "print(\"The image: \", show_data(train_dataset[2]))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "Build a Softmax Classifier Class<br>\n", "<br>\n", "oftmax Class from nn.Module"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class SoftMax(nn.Module):\n", "    \n", "    #Constructor\n", "    def __init__(self, input_size, output_size):\n", "        super().__init__()\n", "        self.linear = nn.Linear(input_size, output_size)\n", "    \n", "    #Prediction\n", "    def forward(self, x):\n", "        \n", "        z = self.linear(x)\n", "        \n", "        return z"]}, {"cell_type": "markdown", "metadata": {}, "source": ["rain_dataset shape"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_dataset[0][0].shape"]}, {"cell_type": "markdown", "metadata": {}, "source": ["he trainset needs to be flattened to 1 column and multiple rows (728)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["input_dim = 28 * 28 #728 rows \n", "output_dim = 10 #10 Categories 0,1,2,3,4,5,6,7,8,9"]}, {"cell_type": "markdown", "metadata": {}, "source": ["reate the model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model = SoftMax(input_dim, output_dim)\n", "print(\"The Model:\\n\", model)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ets see the initialized parameters and their size"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print('W: ',list(model.parameters())[0].size())\n", "print('b: ',list(model.parameters())[1].size())\n", "print(\"The Parameters are: \\n\", model.state_dict())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ets plot the parameters"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["PlotParameters(model)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["oad data into DataLoader"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_loader = DataLoader(dataset = train_dataset, batch_size = 100)\n", "val_loader = DataLoader(dataset = val_dataset, batch_size = 5000)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["et the learning_rate"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["learning_rate = 0.1"]}, {"cell_type": "markdown", "metadata": {}, "source": ["efine optimizer and criterion"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n", "criterion = nn.CrossEntropyLoss()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["rain the model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["epochs = 10\n", "LOSS_List = [] #empty list to store LOSS\n", "Accuracy_List = []\n", "N_test = len(val_dataset)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["raining function"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def train_model(n_epochs):\n", "    for epoch in range(epochs):\n", "        \n", "        for x, y in train_loader:\n", "           \n", "            optimizer.zero_grad()\n", "           \n", "            z = model(x.view(-1, 28 * 28)) #reshaping to 28x28\n", "            \n", "            loss = criterion(z, y)\n", "            \n", "            loss.backward()\n", "           \n", "            optimizer.step()\n", "            \n", "        correct = 0\n", "        print(correct)\n", "        \n", "        #Perform a prediction on the validation data  \n", "        for x_test, y_test in val_loader:\n", "           \n", "            z = model(x_test.view(-1, 28 * 28))\n", "           \n", "            _, yhat = torch.max(z.data, 1) #Take max value from z \n", "           \n", "            correct += (yhat == y_test).sum().item()\n", "            print(correct)\n", "       \n", "        accuracy = correct / N_test\n", "       \n", "        LOSS_List.append(loss.data)\n", "      \n", "        Accuracy_List.append(accuracy)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_model(epochs)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "Analyze the model<br>\n", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["lot the loss and accuracy"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig, ax1 = plt.subplots()\n", "color = 'tab:red'\n", "ax1.plot(LOSS_List,color=color)\n", "ax1.set_xlabel('epoch',color=color)\n", "ax1.set_ylabel('total loss',color=color)\n", "ax1.tick_params(axis='y', color=color)\n", "    \n", "ax2 = ax1.twinx()  \n", "color = 'tab:blue'\n", "ax2.set_ylabel('accuracy', color=color)  \n", "ax2.plot(Accuracy_List, color=color)\n", "ax2.tick_params(axis='y', color=color)\n", "fig.tight_layout()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["lot trained parameters"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["PlotParameters(model)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["lot missclassified examples"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["Softmax_function = nn.Softmax(dim = -1)\n", "count = 0"]}, {"cell_type": "markdown", "metadata": {}, "source": ["lot the first 5 correctly classified samples and their respective probability by using torch.max "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for x,y in val_dataset:\n", "    \n", "    z = model(x.reshape(-1, 28*28))\n", "    _, yhat = torch.max(z, 1)\n", "    \n", "    if yhat == y:\n", "        show_data((x, y))\n", "        plt.show()\n", "        print(\"yhat: \". yhat)\n", "        print(\"Probability of class: \", torch.max(Softmax_function(z).item()))\n", "        count += 1\n", "    \n", "    if count >= 5:\n", "        break"]}, {"cell_type": "markdown", "metadata": {}, "source": ["lot the first 5 missclassified samples and their respective probability by using torch.max "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["count = 0\n", "for x,y in val_dataset:\n", "    \n", "    z = model(x.reshape(-1, 28*28))\n", "    _, yhat = torch.max(z, 1)\n", "    \n", "    if yhat != y:\n", "        show_data((x, y))\n", "        plt.show()\n", "        print(\"yhat: \". yhat)\n", "        print(\"Probability of class: \", torch.max(Softmax_function(z).item()))\n", "        count += 1\n", "    \n", "    if count >= 5:\n", "        break"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}