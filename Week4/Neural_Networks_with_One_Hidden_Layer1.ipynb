{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "Neural Networks with One Hidden Layer<br>\n", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[1]: Imports"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import torch \n", "import torch.nn as nn\n", "import torchvision.transforms as transforms\n", "import torchvision.datasets as dsets\n", "from torch.utils.data import DataLoader, Dataset\n", "import matplotlib.pylab as plt\n", "import numpy as np\n", "torch.manual_seed(0)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[2]<br>\n", "lotting function"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def plot_accuracy_loss(training_results):\n", "    plt.subplot(2, 1, 1)\n", "    plt.plot(training_results['training_loss'], 'r')\n", "    plt.ylabel('loss')\n", "    plt.title('training loss iterations')\n", "    plt.subplot(2, 1, 2)\n", "    plt.plot(training_results['validation_accuracy'])\n", "    plt.ylabel('accuracy')\n", "    plt.xlabel('epochs')   \n", "    plt.show()    "]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[3]<br>\n", "odel Parameters function"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def print_model_parameters(model):\n", "    count = 0\n", "    \n", "    for element in model.state_dict():\n", "        count += 1\n", "        if count %2 != 0:\n", "            print (\"The following are the parameters for the layer \", count // 2 + 1)\n", "        if element.find(\"bias\") != -1:\n", "            print(\"The size of bias: \", model.state_dict()[element].size())\n", "        else:\n", "            print(\"The size of weights: \", model.state_dict()[element].size())\n", "       \n", "# In[4]\n", "#Function to show data (images)\n", "def show_data(data_sample):\n", "    plt.imshow(data_sample.numpy().reshape(28, 28), cmap = 'gray')\n", "    plt.show()            \n", "             \n", "# In[5]\n", "#Class Neural Net with 1 hidden layer\n", "class SimpleNet(nn.Module):\n", "    #Constructor\n", "    def __init__(self, D_in, H, D_out):\n", "        super().__init__()\n", "        self.linear1 = nn.Linear(D_in, H) #input layer\n", "        self.linear2 = nn.Linear(H, D_out) #Output layer\n", "        \n", "    #Prediction\n", "    def forward(self, x):\n", "        x = torch.sigmoid(self.linear1(x))\n", "        x = self.linear2(x) #We want to predict multiple classes so sigmoid function shouldnt be used\n", "        \n", "        return x\n", "        \n", "# In[6]\n", "#Training function\n", "def train_model(model, criterion, train_loader, validation_loader, optimizer, epochs = 100):\n", "    i = 0\n", "    useful_stuff = {'training_loss': [], 'validation_accuracy': []}\n", "    \n", "    for epoch in range(epochs):\n", "        \n", "        for i, (x, y) in enumerate(train_loader):\n", "            \n", "            optimizer.zero_grad()\n", "            \n", "            z = model(x.view(-1, 28*28)) #reshaping to 28*28 \n", "            \n", "            loss = criterion(z, y)\n", "            \n", "            loss.backward()\n", "        \n", "            optimizer.step()\n", "            \n", "            useful_stuff['training_loss'].append(loss.data.item())\n", "     \n", "        correct = 0\n", "        \n", "        for x, y in validation_loader:\n", "            \n", "            z = model(x.view(-1, 28*28)) #reshaping to 28*28\n", "            \n", "            _, label = torch.max(z, 1) #Take class with max probability\n", "            \n", "            correct += (label == y).sum().item() \n", "            \n", "        accuracy = 100 * (correct / len(validation_dataset))\n", "        useful_stuff['validation_accuracy'].append(accuracy)\n", "    return useful_stuff\n", "    \n", "    \n", "# In[7]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["oad Data "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_dataset = dsets.MNIST(root='./data', train = True, download = True, transform = transforms.ToTensor()) #Load train MNIST set and transform to tensor\n", "validation_dataset = dsets.MNIST(root='./data', train = False, download = True, transform = transforms.ToTensor()) #Load non-train MNIST set and transform to tensor"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[8]<br>\n", "reate dataloader, criterion function, optimizer, learning rate"]}, {"cell_type": "markdown", "metadata": {}, "source": ["raind and validation loader"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=2000, shuffle=True)\n", "validation_loader = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=5000, shuffle=False)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["riterion function"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["criterion = nn.CrossEntropyLoss()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["earning rate"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["learning_rate = 0.01"]}, {"cell_type": "markdown", "metadata": {}, "source": ["reate model with input dimension of the images WxH 28*28, 100 neurons and 10 output dim."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model = SimpleNet(784, 100, 10)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["odel parameters"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print_model_parameters(model)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ptimizer"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[9]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["raining the model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["training_results = train_model(model, criterion, train_loader, validation_loader, optimizer, epochs=30)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[10]<br>\n", "lot accuracy and loss"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plot_accuracy_loss(training_results)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["lot the 1st 5 misclassified items"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["count = 0\n", "for x, y in validation_dataset:\n", "    z = model(x.reshape(-1, 28 * 28))\n", "    _,yhat = torch.max(z, 1)\n", "    if yhat != y:\n", "        show_data(x)\n", "        count += 1\n", "    if count >= 5:\n", "        break"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[11]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["se nn.Sequential to build to same model, train it and plot"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model = torch.nn.Sequential(nn.Linear(784, 100), nn.Sigmoid(), nn.Linear(100, 10))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["training_results = train_model(model, criterion, train_loader, validation_loader, optimizer, epochs = 10)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plot_accuracy_loss(training_results)"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}