{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "Convolutional Neural Network with Small Images<br>\n", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[1] Imports"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import torch\n", "import torch.nn as nn\n", "import torchvision.transforms as transforms\n", "import torchvision.datasets as dsets\n", "from torch.utils.data import DataLoader, Dataset\n", "import matplotlib.pyplot as plt\n", "import numpy as np\n", "torch.manual_seed(0)\n", "from matplotlib.pyplot import imshow\n", "import matplotlib.pylab as plt\n", "from PIL import Image\n", "import time"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[2] Plot function"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Define the function for plotting the channels"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def show_data(data_sample):\n", "    plt.imshow(data_sample[0].numpy().reshape(IMAGE_SIZE, IMAGE_SIZE), cmap='gray')\n", "    plt.title('y = ' + str(data_sample[1]))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[3] Create Data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["IMAGE_SIZE = 16"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Create a transform to resize image and convert to tensor"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["composed = transforms.Compose([transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)), transforms.ToTensor()])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Create Dataset from MNIST and apply composed transformation"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["dataset_train = dsets.FashionMNIST(root='.fashion/data', train=True, download=True, transform=composed)\n", "dataset_val = dsets.FashionMNIST(root='.fashion/data', train=False, download=True, transform=composed)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for n, data_sample in enumerate(dataset_val):\n", "    show_data(data_sample)\n", "    plt.show()\n", "    if n == 2:\n", "        break"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n Question: Take a screen shot of the first three images of the validation dataset from the code provided.<br>\n", "              The function show_data<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["show_data(dataset_val[0])\n", "show_data(dataset_val[1])\n", "show_data(dataset_val[2])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[4] Create CNN Class"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class CNN(nn.Module):\n\n", "    # Constructor\n", "    def __init__(self, out_1=16, out_2=32):\n", "        super().__init__()\n", "        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=out_1, kernel_size=5, padding=2)\n", "        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n", "        self.ELU = nn.ELU()\n", "        self.cnn2 = nn.Conv2d(in_channels=out_1, out_channels=out_2, kernel_size=5, padding=2)\n", "        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n", "        self.fc1 = nn.Linear(out_2*4*4, 10)\n\n", "    # Prediction\n", "    def forward(self, x):\n", "        x = self.cnn1(x)\n", "        x = self.ELU(x)\n", "        x = self.maxpool1(x)\n", "        x = self.cnn2(x)\n", "        x = self.ELU(x)\n", "        x = self.maxpool2(x)\n", "        x = x.view(x.size(0), -1)\n", "        x = self.fc1(x)\n", "        return x\n\n", "    # Outputs in each step\n", "    def activations(self, x):\n", "        # This part is for visualization purposes\n", "        z1 = self.cnn1(x)\n", "        a1 = self.ELU(z1)\n", "        out = self.maxpool1(a1)\n", "        z2 = self.cnn2(out)\n", "        a2 = self.ELU(z2)\n", "        out1 = self.maxpool2(a2)\n", "        out2 = out1.view(out1.size(0), -1)\n", "        return z1, a1, out, z2, a2, out1, out2"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[5] Batch Normalization CNN class"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class CNN_BatchNorm(nn.Module):\n", "    # Constructor\n", "    def __init__(self, out_1=16, out_2=32):\n", "        super().__init__()\n", "        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=out_1, kernel_size=5, padding=2)\n", "        self.conv1_bn = nn.BatchNorm2d(out_1)  # To normalize conv2D, we need BatchNorm2D\n", "        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n", "        self.ELU = nn.ELU()\n", "        self.cnn2 = nn.Conv2d(in_channels=out_1, out_channels=out_2, kernel_size=5, padding=2)\n", "        self.conv2_bn = nn.BatchNorm2d(out_2)\n", "        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n", "        self.fc1 = nn.Linear(out_2*4*4, 10)\n", "        self.bn_fc1 = nn.BatchNorm1d(10)  # To normalize linear layer, BatchNorm1D must be used\n\n", "    # Prediction\n", "    def forward(self, x):\n", "        x = self.cnn1(x)\n", "        x = self.conv1_bn(x)\n", "        x = self.ELU(x)\n", "        x = self.maxpool1(x)\n", "        x = self.cnn2(x)\n", "        x = self.conv2_bn(x)\n", "        x = self.ELU(x)\n", "        x = self.maxpool2(x)\n", "        x = x.view(x.size(0), -1)\n", "        x = self.fc1(x)\n", "        x = self.bn_fc1(x)\n", "        return x"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[6] Initialize, create loss function, optimizer and data loaders"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Loss function criterion"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["criterion = nn.CrossEntropyLoss()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["train and val loader"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_loader = DataLoader(dataset=dataset_train, batch_size=100)\n", "validation_loader = DataLoader(dataset=dataset_val, batch_size=100)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Create model_BatchNorm object from CNN_BatchNorm class"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model = CNN_BatchNorm(16, 32)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Optimizer"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["optimizer = torch.optim.SGD(model.parameters(), lr=0.1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[6] Train loop and training"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["start_time = time.time()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["cost_list = []\n", "accuracy_list = []\n", "N_test = len(dataset_val)\n", "n_epochs = 5\n", "for epoch in range(n_epochs):\n", "    cost = 0\n", "    model.train()\n", "    for x, y in train_loader:\n", "        optimizer.zero_grad()\n", "        z = model(x)\n", "        loss = criterion(z, y)\n", "        loss.backward()\n", "        optimizer.step()\n", "        cost += loss.item()\n", "    correct = 0\n", "    # Perform a prediction on the validation data\n", "    model.eval()\n", "    for x_test, y_test in validation_loader:\n", "        z = model(x_test)\n", "        _, yhat = torch.max(z.data, 1)\n", "        correct += (yhat == y_test).sum().item()\n", "    accuracy = correct / N_test\n", "    accuracy_list.append(accuracy)\n", "    cost_list.append(cost)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[7] Analyze Results and Compare"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Plot the loss and accuracy"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig, ax1 = plt.subplots()\n", "color = 'tab:red'\n", "ax1.plot(cost_list, color=color)\n", "ax1.set_xlabel('epoch', color=color)\n", "ax1.set_ylabel('Cost', color=color)\n", "ax1.tick_params(axis='y', color=color)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ax2 = ax1.twinx()\n", "color = 'tab:blue'\n", "ax2.set_ylabel('accuracy', color=color)\n", "ax2.set_xlabel('epoch', color=color)\n", "ax2.plot(accuracy_list, color=color)\n", "ax2.tick_params(axis='y', color=color)\n", "fig.tight_layout()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}