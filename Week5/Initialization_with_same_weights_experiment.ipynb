{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "Neural Network same weights Initialization Experiment<br>\n", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[1] Imports"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import torch \n", "import torch.nn as nn\n", "import matplotlib.pylab as plt\n", "torch.manual_seed(0)\n", "import torchvision.datasets as dsets\n", "import torchvision.transforms as transforms\n", "from torch.utils.data import DataLoader"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[2] Creating Data"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Create the train dataset"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_dataset = dsets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Create the validation dataset"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["validation_dataset = dsets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Create Dataloader for both train dataset and validation dataset"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=2000, shuffle=True)\n", "validation_loader = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=5000, shuffle=False)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[3] Creating Networks using ModuleList "]}, {"cell_type": "markdown", "metadata": {}, "source": ["Network with relu activation and He_initialization with relu"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class Network_He(nn.Module):\n", "    \n", "    # Constructor\n", "    def __init__(self, Layers):\n", "        super().__init__()\n", "        self.hidden = nn.ModuleList()\n", "        for input_size, output_size in zip(Layers, Layers[1:]):\n", "            linear = nn.Linear(input_size, output_size)\n", "            torch.nn.init.kaiming_uniform_(linear.weight, nonlinearity='relu')\n", "            self.hidden.append(linear)\n\n", "    # Prediction\n", "    def forward(self, x):\n", "        L = len(self.hidden)\n", "        for (l, linear_transform) in zip(range(L), self.hidden):\n", "            if l < L - 1:\n", "                x = torch.relu(linear_transform(x))\n", "            else:\n", "                x = linear_transform(x)\n", "        return x"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Network with relu activation and uniform initialization"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class Network_Uniform(nn.Module):\n", "    \n", "    # Constructor\n", "    def __init__(self, Layers):\n", "        super().__init__()\n", "        self.hidden = nn.ModuleList()\n", "        for input_size, output_size in zip(Layers, Layers[1:]):\n", "            linear = nn.Linear(input_size,output_size)\n", "            linear.weight.data.uniform_(0, 1)\n", "            self.hidden.append(linear)\n", "    \n", "    # Prediction\n", "    def forward(self, x):\n", "        L = len(self.hidden)\n", "        for (l, linear_transform) in zip(range(L), self.hidden):\n", "            if l < L - 1:\n", "                x = torch.relu(linear_transform(x))\n", "            else:\n", "                x = linear_transform(x)\n", "                \n", "        return x\n", "  "]}, {"cell_type": "markdown", "metadata": {}, "source": ["Network with relu and Default Initilization"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class Network(nn.Module):\n", "    \n", "    # Constructor\n", "    def __init__(self, Layers):\n", "        super().__init__()\n", "        self.hidden = nn.ModuleList()\n", "        for input_size, output_size in zip(Layers, Layers[1:]):\n", "            linear = nn.Linear(input_size, output_size)\n", "            self.hidden.append(linear)\n", "        \n", "    def forward(self, x):\n", "        L=len(self.hidden)\n", "        for (l, linear_transform) in zip(range(L), self.hidden):\n", "            if l < L - 1:\n", "                x = torch.relu(linear_transform(x))\n", "            else:\n", "                x = linear_transform(x)\n", "                \n", "        return x"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Network with relu and Same Initilization"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class Network_Same(nn.Module):\n", "    \n", "    # Constructor\n", "    def __init__(self, Layers):\n", "        super().__init__()\n", "        self.hidden = nn.ModuleList()\n", "        for input_size, output_size in zip(Layers, Layers[1:]):\n", "            linear = nn.Linear(input_size, output_size)\n", "            self.hidden.append(linear)\n", "        \n", "    def forward(self, x):\n", "        L=len(self.hidden)\n", "        for (l, linear_transform) in zip(range(L), self.hidden):\n", "            if l < L - 1:\n", "                x = torch.relu(linear_transform(x))\n", "            else:\n", "                x = linear_transform(x)\n", "                \n", "        return x"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Network with tanh activation and Xavier Initialization for Tanh"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class Network_Xavier(nn.Module):\n", "    \n", "    # Constructor\n", "    def __init__(self, Layers):\n", "        super().__init__()\n", "        self.hidden = nn.ModuleList()\n", "        for input_size, output_size in zip(Layers, Layers[1:]):\n", "            linear = nn.Linear(input_size, output_size)\n", "            torch.nn.init.xavier_uniform_(linear.weight)\n", "            self.hidden.append(linear)\n", "    \n", "    # Prediction\n", "    def forward(self, x):\n", "        L = len(self.hidden)\n", "        for (l, linear_transform) in zip(range(L), self.hidden):\n", "            if l < L - 1:\n", "                x = torch.tanh(linear_transform(x))\n", "            else:\n", "                x = linear_transform(x)\n", "        return x"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[5] Training function"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def train(model, criterion, train_loader, validation_loader, optimizer, epochs = 100):\n", "    i = 0\n", "    loss_accuracy = {'training_loss':[], 'validation_accuracy':[]}  \n", "    \n", "    for epoch in range(epochs):\n", "        for i,(x, y) in enumerate(train_loader):\n", "            optimizer.zero_grad()\n", "            z = model(x.view(-1, 28 * 28))\n", "            loss = criterion(z, y)\n", "            loss.backward()\n", "            optimizer.step()\n", "            loss_accuracy['training_loss'].append(loss.data.item())\n", "            \n", "        correct = 0\n", "        for x, y in validation_loader:\n", "            yhat = model(x.view(-1, 28 * 28))\n", "            _, label = torch.max(yhat, 1)\n", "            correct += (label==y).sum().item()\n", "        accuracy = 100 * (correct / len(validation_dataset))\n", "        loss_accuracy['validation_accuracy'].append(accuracy)\n", "        \n", "    return loss_accuracy"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[4] Creating the layer for ModuleList"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["input_dim = 28*28\n", "output_dim = 10\n", "layers = [input_dim, 100, 10, 100, 10, 100, output_dim]\n", "epochs = 10"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[5] Creating loss function and Optimizers and Networks for comparison"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["criterion = nn.CrossEntropyLoss()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["First model with default initialization"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model = Network(layers)\n", "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n", "training_results = train(model, criterion, train_loader, validation_loader, optimizer, epochs=epochs)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["2nd model with Uniform Initialization"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model_Uniform = Network_Uniform(layers)\n", "optimizer = torch.optim.SGD(model_Uniform.parameters(), lr=0.01)\n", "training_results_Uniform = train(model_Uniform, criterion, train_loader, validation_loader, optimizer, epochs=epochs)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["3rd model with Xavier_initialization"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model_Xavier = Network_Xavier(layers)\n", "optimizer = torch.optim.SGD(model_Xavier.parameters(), lr=0.01)\n", "training_results_Xavier = train(model_Xavier, criterion, train_loader, validation_loader, optimizer, epochs=epochs)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["4th model with He_initialization"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model_He = Network_He(layers)\n", "optimizer = torch.optim.SGD(model_He.parameters(), lr=0.01)\n", "training_results_He = train(model_He, criterion, train_loader, validation_loader, optimizer, epochs=epochs)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["5th model with the same initializations for all neurons"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model_Same = Network_Same(layers)\n", "model_Same.state_dict()['hidden.0.weight'][:]=1.0\n", "model_Same.state_dict()['hidden.1.weight'][:]=1.0\n", "model_Same.state_dict()['hidden.2.weight'][:]=1.0\n", "model_Same.state_dict()['hidden.3.weight'][:]=1.0\n", "model_Same.state_dict()['hidden.4.weight'][:]=1.0\n", "model_Same.state_dict()['hidden.5.weight'][:]=1.0\n", "model_Same.state_dict()['hidden.0.bias'][:]=0.0\n", "model_Same.state_dict()['hidden.1.bias'][:]=0.0\n", "model_Same.state_dict()['hidden.2.bias'][:]=0.0\n", "model_Same.state_dict()['hidden.3.bias'][:]=0.0\n", "model_Same.state_dict()['hidden.4.bias'][:]=0.0\n", "model_Same.state_dict()['hidden.5.bias'][:]=0.0\n", "model_Same.state_dict()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["optimizer = torch.optim.SGD(model_Same.parameters(), lr=0.01)\n", "training_results_Same = train(model_Same, criterion, train_loader, validation_loader, optimizer, epochs=epochs)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[5] Plotting results"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Plot the loss"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.plot(training_results_Xavier['training_loss'], label='Xavier')\n", "plt.plot(training_results_He['training_loss'], label='He')\n", "plt.plot(training_results['training_loss'], label='Default')\n", "plt.plot(training_results_Uniform['training_loss'], label='Uniform')\n", "plt.plot(training_results_Same['training_loss'], label='Same')\n", "plt.ylabel('loss')\n", "plt.xlabel('iteration ')  \n", "plt.title('training loss iterations')\n", "plt.legend()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Plot the accuracy"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.plot(training_results_Xavier['validation_accuracy'], label='Xavier')\n", "plt.plot(training_results_He['validation_accuracy'], label='He')\n", "plt.plot(training_results['validation_accuracy'], label='Default')\n", "plt.plot(training_results_Uniform['validation_accuracy'], label='Uniform') \n", "plt.plot(training_results_Same['validation_accuracy'], label='Same') \n", "plt.ylabel('validation accuracy')\n", "plt.xlabel('epochs')   \n", "plt.legend()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}