{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "Comparing Neural Network Dropout vs Non in Classification<br>\n", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[1] Imports"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import matplotlib.pyplot as plt \n", "import numpy as np\n", "import torch\n", "import torch.nn as nn\n", "from matplotlib.colors import ListedColormap\n", "from torch.utils.data import Dataset"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[2] Plotting function"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def plot_decision_regions_3class(data_set, model=None):\n", "    cmap_light = ListedColormap([ '#0000FF','#FF0000'])\n", "    cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#00AAFF'])\n", "    X = data_set.x.numpy()\n", "    y = data_set.y.numpy()\n", "    h = .02\n", "    x_min, x_max = X[:, 0].min() - 0.1, X[:, 0].max() + 0.1 \n", "    y_min, y_max = X[:, 1].min() - 0.1, X[:, 1].max() + 0.1 \n", "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n", "    newdata = np.c_[xx.ravel(), yy.ravel()]\n", "    \n", "    Z = data_set.multi_dim_poly(newdata).flatten()\n", "    f = np.zeros(Z.shape)\n", "    f[Z > 0] = 1\n", "    f = f.reshape(xx.shape)\n", "    if model != None:\n", "        model.eval()\n", "        XX = torch.Tensor(newdata)\n", "        _, yhat = torch.max(model(XX), 1)\n", "        yhat = yhat.numpy().reshape(xx.shape)\n", "        plt.pcolormesh(xx, yy, yhat, cmap=cmap_light)\n", "        plt.contour(xx, yy, f, cmap=plt.cm.Paired)\n", "    else:\n", "        plt.contour(xx, yy, f, cmap=plt.cm.Paired)\n", "        plt.pcolormesh(xx, yy, f, cmap=cmap_light) \n", "    plt.title(\"decision region vs True decision boundary\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[3] Creating Data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class Data(Dataset):\n", "    \n", "    # Constructor\n", "    def __init__(self, N_SAMPLES=1000, noise_std=0.15, train=True):\n", "        a = np.matrix([-1, 1, 2, 1, 1, -3, 1]).T\n", "        self.x = np.matrix(np.random.rand(N_SAMPLES, 2))\n", "        self.f = np.array(a[0] + (self.x) * a[1:3] + np.multiply(self.x[:, 0], self.x[:, 1]) * a[4] + np.multiply(self.x, self.x) * a[5:7]).flatten()\n", "        self.a = a\n", "       \n", "        self.y = np.zeros(N_SAMPLES)\n", "        self.y[self.f > 0] = 1\n", "        self.y = torch.from_numpy(self.y).type(torch.LongTensor)\n", "        self.x = torch.from_numpy(self.x).type(torch.FloatTensor)\n", "        self.x = self.x + noise_std * torch.randn(self.x.size())\n", "        self.f = torch.from_numpy(self.f)\n", "        self.a = a\n", "        if train == True:\n", "            torch.manual_seed(1)\n", "            self.x = self.x + noise_std * torch.randn(self.x.size())\n", "            torch.manual_seed(0)\n", "        \n", "    # Getter        \n", "    def __getitem__(self, index):    \n", "        return self.x[index], self.y[index]\n", "    \n", "    # Get Length\n", "    def __len__(self):\n", "        return self.len\n", "    \n", "    # Plot the diagram\n", "    def plot(self):\n", "        X = data_set.x.numpy()\n", "        y = data_set.y.numpy()\n", "        h = .02\n", "        x_min, x_max = X[:, 0].min(), X[:, 0].max()\n", "        y_min, y_max = X[:, 1].min(), X[:, 1].max() \n", "        xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n", "        Z = data_set.multi_dim_poly(np.c_[xx.ravel(), yy.ravel()]).flatten()\n", "        f = np.zeros(Z.shape)\n", "        f[Z > 0] = 1\n", "        f = f.reshape(xx.shape)\n", "        \n", "        plt.title('True decision boundary  and sample points with noise ')\n", "        plt.plot(self.x[self.y == 0, 0].numpy(), self.x[self.y == 0,1].numpy(), 'bo', label='y=0') \n", "        plt.plot(self.x[self.y == 1, 0].numpy(), self.x[self.y == 1,1].numpy(), 'ro', label='y=1')\n", "        plt.contour(xx, yy, f,cmap=plt.cm.Paired)\n", "        plt.xlim(0,1)\n", "        plt.ylim(0,1)\n", "        plt.legend()\n", "    \n", "    # Make a multidimension ploynomial function\n", "    def multi_dim_poly(self, x):\n", "        x = np.matrix(x)\n", "        out = np.array(self.a[0] + (x) * self.a[1:3] + np.multiply(x[:, 0], x[:, 1]) * self.a[4] + np.multiply(x, x) * self.a[5:7])\n", "        out = np.array(out)\n", "        return out"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[4] Creating Network "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class Network(nn.Module):\n\n", "    # Constructor\n", "    def __init__(self, D_in, H1, H2, D_out, p=0): # dropout disabled by default p=0\n", "        super().__init__()\n", "        self.drop = nn.Dropout(p=p) # Dropout with p \n", "        self.linear1 = nn.Linear(D_in, H1)\n", "        self.linear2 = nn.Linear(H1, H2)\n", "        self.linear3 = nn.Linear(H2, D_out)\n", "        \n", "    # Prediction\n", "    def forward(self, x):\n", "        x = self.linear1(x)\n", "        x = self.drop(x)\n", "        x = torch.relu(x)\n", "        x = self.linear2(x)\n", "        x = self.drop(x)\n", "        x = torch.relu(x)\n", "        x = self.linear3(x)\n", "        return x\n", "        \n", "# In[5] Training function"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def train_model(epochs):\n", "    \n", "    for epoch in range(epochs):\n", "        #all the samples are used for training \n", "        yhat = model(data_set.x)\n", "        yhat_dropout = model_dropout(data_set.x)\n", "        loss = criterion(yhat, data_set.y)\n", "        loss_dropout = criterion(yhat_dropout, data_set.y)\n\n", "        #store the loss for both the training and validation data for both models \n", "        LOSS['training data no dropout'].append(loss.item())\n", "        LOSS['validation data no dropout'].append(criterion(model(validation_set.x), validation_set.y).item())\n", "        LOSS['training data dropout'].append(loss_dropout.item())\n", "        model_dropout.eval()\n", "        LOSS['validation data dropout'].append(criterion(model_dropout(validation_set.x), validation_set.y).item())\n", "        model_dropout.train()\n", "        optimizer.zero_grad()\n", "        optimizer_dropout.zero_grad()\n", "        loss.backward()\n", "        loss_dropout.backward()\n", "        optimizer.step()\n", "        optimizer_dropout.step()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[6] accuracy function"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def accuracy(model, data_set):\n", "    _, yhat = torch.max(model(data_set.x), 1)\n", "    return (yhat == data_set.y).numpy().mean()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[7] Create Dataset object and plot"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["data_set = Data(noise_std=0.2)\n", "data_set.plot()\n", "validation_set = Data(train=False)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[8] Create models with dropout and without, Create optimizer and criterion"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model = Network(2, 300, 300, 2)\n", "model_dropout = Network(2, 300, 300, 2, p=0.2) #dropout of probability 0.5"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model_dropout.train() # Set model to train model. It is trian by default but good practice to set it anyway"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n", "optimizer_dropout = torch.optim.Adam(model_dropout.parameters(), lr=0.01)\n", "criterion = torch.nn.CrossEntropyLoss()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[9] Initialize the Loss dictionary to store Loss"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["LOSS = {}\n", "LOSS['training data no dropout'] = []\n", "LOSS['validation data no dropout'] = []\n", "LOSS['training data dropout'] = []\n", "LOSS['validation data dropout'] = []"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[10] train models for 500 epochs and evaluate"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_model(500)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Set model_dropout to evaluation mode. This is done to disable dropout"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model_dropout.eval()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Print out the accuracy of the model without dropout"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"The accuracy of the model without dropout: \", accuracy(model, validation_set))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Print out the accuracy of the model with dropout"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"The accuracy of the model with dropout: \", accuracy(model_dropout, validation_set))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[11] Plot results to show decision model for model and model_dropout"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Plot the decision boundary and the prediction"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plot_decision_regions_3class(data_set) # What the prediction should be"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The model without dropout"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plot_decision_regions_3class(data_set, model)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The model with dropout"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plot_decision_regions_3class(data_set, model_dropout)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["LOSS Plot"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(6.1, 10))\n", "def plot_LOSS():\n", "    for key, value in LOSS.items():\n", "        plt.plot(np.log(np.array(value)), label=key)\n", "        plt.legend()\n", "        plt.xlabel(\"iterations\")\n", "        plt.ylabel(\"Log of cost or total loss\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plot_LOSS()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}