{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "Dataset for Images<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import torch\n", "from PIL import Image\n", "import pandas as pd\n", "import os\n", "from matplotlib.pyplot import imshow\n", "import matplotlib.pyplot as plt\n", "from torch.utils.data import Dataset, DataLoader\n", "import torchvision.transforms as transforms"]}, {"cell_type": "markdown", "metadata": {}, "source": ["e will use MNIST dataset, 28x28x1 images<br>\n", "he dataset has 10 labels or classes"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["directory = r\"C:\\*******\\Deep Neural Networks with PyTorch\\Week 1\"\n", "csv_file = 'index.csv'\n", "csv_path = os.path.join(directory,csv_file)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["data_name = pd.read_csv((csv_path))\n", "data_name.head() #Lets view the dataframe"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print('File name:', data_name.iloc[0,1])\n", "print('class or y:', data_name.iloc[0,0])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for i in range(len(data_name)): #Lets plot all the images in the imageset\n", "    image_name = data_name.iloc[i,1] #we iterate through every image in the i'th row, 2nd column.\n", "    image_path = os.path.join(directory,image_name) #We set the image path \n", "    image = Image.open(image_path) #We open the image from its path\n", "    #Lets see the image\n", "    plt.imshow(image, cmap = 'gray', vmin = 0, vmax = 255)\n", "    plt.title(data_name.iloc[i,1])\n", "    plt.show()\n", "    "]}, {"cell_type": "markdown", "metadata": {}, "source": ["ets create a dataset class"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class Dataset(Dataset):\n", "    def __init__(self, csv_file, data_dir, transform = None):\n", "        \n", "        self.transform = transform\n", "        self.data_dir = data_dir\n", "        data_dircsv_file = os.path.join(self.data_dir,csv_file)\n", "        self.data_name = pd.read_csv(data_dircsv_file)\n", "        self.len = self.data_name.shape[0]\n", "        \n", "    def __lef__(self):\n", "        return self.len\n", "    \n", "    def __getitem__(self, idx):\n", "        \n", "        img_name = os.path.join(self.data_dir, self.data_name.iloc[idx, 1])\n", "        image = Image.open(img_name)\n", "        \n", "        y = self.data_name.iloc[idx, 0]\n", "        \n", "        if self.transform:\n", "            image = self.transform(image)\n", "            return image, y"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ets use torchvision pre-built transforms for images"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["transforms.CenterCrop(20) #Lets crop the image to 20x20\n", "transforms.ToTensor() #Converting the image to a tensor"]}, {"cell_type": "markdown", "metadata": {}, "source": ["r we can combine the transforms<br>\n", "ets compose the transforms"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["croptensor_data_transform = transforms.Compose([transforms.CenterCrop(20), transforms.ToTensor()])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ow we apply the composed transforms to the dataset constructor"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["dataset = Dataset(csv_file = csv_file, data_dir = directory, transform = croptensor_data_transform)\n", "dataset[0][0].shape #The dataset is 20x20x1"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ets try a prebuilt dataset from torchvision"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import torchvision.datasets as dsets"]}, {"cell_type": "markdown", "metadata": {}, "source": ["e creat the dataset object<br>\n", "oot is root directory of dataset, train parameter indicates if we want to use training or testing sets. <br>\n", "ownload = True: downlaods the dataset into the directory. We set transform parameter to convert image to tensor."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["dataset = dsets.MNIST(root = './data', train = False, download = True, transform = transforms.ToTensor)"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}