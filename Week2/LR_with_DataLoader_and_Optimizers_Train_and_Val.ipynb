{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "Linear Regression with DataLoader, Pytorch way<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import torch\n", "from torch import nn\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "from mpl_toolkits import mplot3d\n", "from torch.utils.data import Dataset, DataLoader\n", "from torch import optim"]}, {"cell_type": "markdown", "metadata": {}, "source": ["reating Data Class"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class Data(Dataset):\n", "    \n", "    #Constructor\n", "    def __init__(self, train = True):\n", "            self.x = torch.arange(-3, 3, 0.1).view(-1, 1)\n", "            self.f = -3 * self.x + 1\n", "            self.y = self.f + 0.1 * torch.randn(self.x.size())\n", "            self.len = self.x.shape[0]\n", "            \n", "            #Creating outliers \n", "            if train == True:\n", "                self.y[0] = 0\n", "                self.y[50:55] = 20\n", "            else:\n", "                pass\n", "      \n", "    #Getter\n", "    def __getitem__(self, index):    \n", "        return self.x[index], self.y[index]\n", "    \n", "    #Get Length\n", "    def __len__(self):\n", "        return self.len"]}, {"cell_type": "markdown", "metadata": {}, "source": ["reating random data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["torch.manual_seed(1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["reating train_data object and validation data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_data = Data() \n", "val_data = Data(train = False) "]}, {"cell_type": "markdown", "metadata": {}, "source": ["lot out training points"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.plot(train_data.x.numpy(), train_data.y.numpy(), 'xr',label=\"training data \")\n", "plt.plot(train_data.x.numpy(), train_data.f.numpy(),label=\"true function  \")\n", "plt.xlabel('x')\n", "plt.ylabel('y')\n", "plt.legend()\n", "plt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class linear_regression(nn.Module): #Creating linear_regression class with attributes from nn.Module \n\n", "    #Constructor\n", "    def __init__(self, input_size, output_size):\n", "        super().__init__() #Inheriting methods from parent class nn.module\n", "        self.linear = nn.Linear(input_size, output_size)\n", "        \n", "    #Prediction\n", "    def forward(self, x):\n", "        yhat = self.linear(x)\n", "        return yhat\n", "    "]}, {"cell_type": "markdown", "metadata": {}, "source": ["sing Pytorch built-in functions to create a criterion function<br>\n", "sing the MSE loss"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["criterion = nn.MSELoss()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["reate a DataLoader object"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["trainloader = DataLoader(dataset = train_data, batch_size = 1) #batch_size 1"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Create Learning Rate list, the error lists and the MODELS list"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["learning_rates=[0.0001, 0.001, 0.01, 0.1]\n", "train_error=torch.zeros(len(learning_rates))\n", "validation_error=torch.zeros(len(learning_rates))\n", "MODELS=[]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Define the train model function and train the model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def train_model_with_lr (iter, lr_list):\n", "    \n", "    #iterate through different learning rates \n", "    for i, lr in enumerate(lr_list):\n", "        \n", "        model = linear_regression(1, 1) #LR with 1 input and 1 output\n", "        \n", "        optimizer = optim.SGD(model.parameters(), lr = lr) #SGD Optimizer \n", "        \n", "        for epoch in range(iter):\n", "            \n", "            for x, y in trainloader:\n", "                yhat = model(x) #prediction\n", "                \n", "                loss = criterion(yhat, y) #loss calculation\n", "                \n", "                optimizer.zero_grad() #Zeroing gradient\n", "                \n", "                loss.backward() #backward pass\n", "                \n", "                optimizer.step() #Re-initialization\n", "                \n", "                print(model.state_dict()) #Printing the updated parameters for each iteration\n", "                \n", "        #Training Data\n", "        Yhat = model(train_data.x)\n", "        \n", "        train_loss = criterion(Yhat, train_data.y)\n", "        \n", "        train_error[i] = train_loss.item()\n", "    \n", "        #Validation Data\n", "        Yhat = model(val_data.x)\n", "        \n", "        val_loss = criterion(Yhat, val_data.y)\n", "        \n", "        validation_error[i] = val_loss.item()\n", "        \n", "        MODELS.append(model)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_model_with_lr(10, learning_rates)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["lot the training loss and validation loss<br>\n", "alidation error will be smaller because Outliers were added to the train_data for visualization <br>\n", "lotting log plot due to learning being in order of 10"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.semilogx(np.array(learning_rates), train_error.numpy(), label = 'training loss/total Loss') \n", "plt.semilogx(np.array(learning_rates), validation_error.numpy(), label = 'validation cost/total Loss')\n", "plt.ylabel('Cost\\ Total Loss')\n", "plt.xlabel('learning rate')\n", "plt.legend()\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["lot the predictions"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["i = 0\n", "for model, learning_rate in zip(MODELS, learning_rates):\n", "    \n", "    yhat = model(val_data.x) #Making predictions on Val_data\n", "    \n", "    plt.plot(val_data.x.numpy(), yhat.detach().numpy(), label = 'lr:' + str(learning_rate)) #Plot yhat for each val_data.x\n", "    \n", "    print('i', yhat.detach().numpy()[0:3])\n", "    \n", "#Plotting learning rate versus validation data. \n", "plt.plot(val_data.x.numpy(), val_data.f.numpy(), 'or', label = 'validation data')\n", "plt.xlabel('x')\n", "plt.ylabel('y')\n", "plt.legend()\n", "plt.show()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}