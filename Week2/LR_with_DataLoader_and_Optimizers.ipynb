{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "Linear Regression with DataLoader, Pytorch way<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import torch\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "from mpl_toolkits import mplot3d\n", "from torch.utils.data import Dataset, DataLoader"]}, {"cell_type": "markdown", "metadata": {}, "source": ["dd a class plot_error_surfaces to visualize the data space and parameters."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class plot_error_surfaces(object):\n", "    \n", "    # Constructor\n", "    def __init__(self, w_range, b_range, X, Y, n_samples = 30, go = True):\n", "        W = np.linspace(-w_range, w_range, n_samples)\n", "        B = np.linspace(-b_range, b_range, n_samples)\n", "        w, b = np.meshgrid(W, B)    \n", "        Z = np.zeros((30, 30))\n", "        count1 = 0\n", "        self.y = Y.numpy()\n", "        self.x = X.numpy()\n", "        for w1, b1 in zip(w, b):\n", "            count2 = 0\n", "            for w2, b2 in zip(w1, b1):\n", "                Z[count1, count2] = np.mean((self.y - w2 * self.x + b2) ** 2)\n", "                count2 += 1\n", "            count1 += 1\n", "        self.Z = Z\n", "        self.w = w\n", "        self.b = b\n", "        self.W = []\n", "        self.B = []\n", "        self.LOSS = []\n", "        self.n = 0\n", "        if go == True:\n", "            plt.figure()\n", "            plt.figure(figsize = (7.5, 5))\n", "            plt.axes(projection = '3d').plot_surface(self.w, self.b, self.Z, rstride = 1, cstride = 1, cmap = 'viridis', edgecolor = 'none')\n", "            plt.title('Loss Surface')\n", "            plt.xlabel('w')\n", "            plt.ylabel('b')\n", "            plt.show()\n", "            plt.figure()\n", "            plt.title('Loss Surface Contour')\n", "            plt.xlabel('w')\n", "            plt.ylabel('b')\n", "            plt.contour(self.w, self.b, self.Z)\n", "            plt.show()\n", "            \n", "    # Setter\n", "    def set_para_loss(self, model, loss):\n", "        self.n = self.n + 1\n", "        self.LOSS.append(loss)\n", "        self.W.append(list(model.parameters())[0].item())\n", "        self.B.append(list(model.parameters())[1].item())\n", "    \n", "    # Plot diagram\n", "    def final_plot(self): \n", "        ax = plt.axes(projection = '3d')\n", "        ax.plot_wireframe(self.w, self.b, self.Z)\n", "        ax.scatter(self.W, self.B, self.LOSS, c = 'r', marker = 'x', s = 200, alpha = 1)\n", "        plt.figure()\n", "        plt.contour(self.w, self.b, self.Z)\n", "        plt.scatter(self.W, self.B, c = 'r', marker = 'x')\n", "        plt.xlabel('w')\n", "        plt.ylabel('b')\n", "        plt.show()\n", "        \n", "    # Plot diagram    \n", "    def plot_ps(self):\n", "        plt.subplot(121)\n", "        plt.ylim()\n", "        plt.plot(self.x, self.y, 'ro', label = \"training points\")\n", "        plt.plot(self.x, self.W[-1] * self.x + self.B[-1], label = \"estimated line\")\n", "        plt.xlabel('x')\n", "        plt.ylabel('y')\n", "        plt.ylim((-10, 15))\n", "        plt.title('Data Space Iteration: ' + str(self.n))\n", "        plt.subplot(122)\n", "        plt.contour(self.w, self.b, self.Z)\n", "        plt.scatter(self.W, self.B, c = 'r', marker = 'x')\n", "        plt.title('Loss Surface Contour Iteration' + str(self.n) )\n", "        plt.xlabel('w')\n", "        plt.ylabel('b')\n", "        plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["reating random data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["torch.manual_seed(1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["reate Data class to create dataset objects"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class Data(Dataset):\n", "    \n", "    #Constructor\n", "    def __init__(self):\n", "        self.x = torch.arange(-3, 3, 0.1).view(-1, 1)\n", "        self.f = 1 * self.x - 1\n", "        self.y = self.f + 0.1 * torch.randn(self.x.size())\n", "        self.len = self.x.shape[0]\n", "        \n", "    #Getter\n", "    def __getitem__(self,index):    \n", "        return self.x[index],self.y[index]\n", "    \n", "    #Get Length\n", "    def __len__(self):\n", "        return self.len"]}, {"cell_type": "markdown", "metadata": {}, "source": ["reating Data object dataset"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["dataset = Data()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ets plot Y, X, f"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.plot(dataset.x.numpy(), dataset.y.numpy(), 'rx', label = 'y')\n", "plt.plot(dataset.x.numpy(), dataset.f.numpy(), label = 'f')\n", "plt.xlabel('x')\n", "plt.ylabel('y')\n", "plt.legend()\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "Creating the model for Linear Regression and Total Loss function (Cost)<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from torch import nn, optim #Importing nn class and optimizer"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class linear_regression(nn.Module): #Creating linear_regression class with attributes from nn.Module \n\n", "    #Constructor\n", "    def __init__(self, input_size, output_size):\n", "        super().__init__() #Inheriting methods from parent class nn.module\n", "        self.linear = nn.Linear(input_size, output_size)\n", "        \n", "    #Prediction\n", "    def forward(self, x):\n", "        yhat = self.linear(x)\n", "        return yhat"]}, {"cell_type": "markdown", "metadata": {}, "source": ["sing Pytorch built-in functions to create a criterion function<br>\n", "sing the MSE loss"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["criterion = nn.MSELoss()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ets create a Linear regression object and optimizer object"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model = linear_regression(1,1)\n", "#We will use Stochastic Gradient Descent, SGD,  as the optimizer\n", "optimizer = optim.SGD(model.parameters(), lr = 0.01) #model.parameters() takes our model parameters created in dataset"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ets check the parameters"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["list(model.parameters())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ets check the optimizer dictionary"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["optimizer.state_dict()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["reate a DataLoader object"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["trainloader = DataLoader(dataset = dataset, batch_size = 1)\n", "#Pytorch automatically and randomly initializes parameters, as seen using model.state_dict()\n", "model.state_dict()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ets specify the parameters to make the process longer and visualize the training"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model.state_dict()['linear.weight'][0] = -15\n", "model.state_dict()['linear.bias'][0] = -10"]}, {"cell_type": "markdown", "metadata": {}, "source": ["reate plot surface object"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["get_surface = plot_error_surfaces(15, 13, dataset.x, dataset.y, 30, go = True)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "Training the model using Batch Gradient Descent<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["LOSS_BGD = []"]}, {"cell_type": "markdown", "metadata": {}, "source": ["rain Model function"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def train_model_BGD(iter):\n", "    for epoch in range(iter):\n", "        for x,y in trainloader:\n", "            \n", "            yhat = model(x) #Predict yhat using initialized parameters\n", "            \n", "            loss = criterion(yhat, y) #Calculate the loss MSE \n", "            \n", "            get_surface.set_para_loss(model, loss.tolist()) #Plot  \n", "            \n", "            #store the loss in the list LOSS_BGD\n", "            LOSS_BGD.append(loss) #Add the loss to the list LOSS_BGD\n", "            \n", "            optimizer.zero_grad() #Zeros the gradient because otherwise pytorch accumulates it\n", "            \n", "            loss.backward() \n", "            optimizer.step() #Updates parameters\n", "            \n", "            get_surface.plot_ps()\n", "        \n", "        \n", "#Now we train the model\n", "train_model_BGD(5)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ets see the parameters of the model after 5 epochs"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model.state_dict()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "Lets try a different learning rate.<br>\n", "<br>\n", "nitializing the new model1 with lr = 0.1"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model1 = linear_regression(1,1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["anually Initializing the parameters "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model1.state_dict()['linear.weight'][0] = -15\n", "model1.state_dict()['linear.bias'][0] = -10"]}, {"cell_type": "markdown", "metadata": {}, "source": ["nitializing the plot"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["get_surface = plot_error_surfaces(15, 13, dataset.x, dataset.y, 30, go = False)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["reate a DataLoader object"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["trainloader = DataLoader(dataset = dataset, batch_size = 1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["et the optimizer"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["optimizer = optim.SGD(model1.parameters(), lr = 0.1) #model.parameters() takes our model parameters created in dataset"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["LOSS_BGD1 = []"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def train_model_BGD1(iter):\n", "    for epoch in range(iter):\n", "        for x,y in trainloader:\n", "            \n", "            yhat = model1(x) #Predict yhat using initialized parameters\n", "            \n", "            loss = criterion(yhat, y) #Calculate the loss MSE \n", "            \n", "            get_surface.set_para_loss(model1, loss.tolist()) #Plot  \n", "            \n", "            #store the loss in the list LOSS_BGD\n", "            LOSS_BGD1.append(loss) #Add the loss to the list LOSS_BGD\n", "            \n", "            optimizer.zero_grad() #Zeros the gradient because otherwise pytorch accumulates it\n", "            \n", "            loss.backward() \n", "            optimizer.step() #Updates parameters\n", "            \n", "            get_surface.plot_ps()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["rain model with lr = 0.1"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_model_BGD1(5)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ets see the parameters of the model after 5 epochs"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model1.state_dict()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.plot(LOSS_BGD,label = \" Batch Gradient Descent with lr 0.01\")\n", "plt.plot(LOSS_BGD1, label = \" Batch Gradient Descent with lr 0.1\", linestyle='dashed')\n", "plt.xlabel('epoch')\n", "plt.ylabel('Cost/ total loss')\n", "plt.legend()\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "LETS TRY Adam optimizer<br>\n", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["nitializing the new model1 with lr = 0.1"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model2 = linear_regression(1,1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["anually Initializing the parameters "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model2.state_dict()['linear.weight'][0] = -15\n", "model2.state_dict()['linear.bias'][0] = -10"]}, {"cell_type": "markdown", "metadata": {}, "source": ["nitializing the plot"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["get_surface = plot_error_surfaces(15, 13, dataset.x, dataset.y, 30, go = False)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["reate a DataLoader object"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["trainloader = DataLoader(dataset = dataset, batch_size = 1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["et the optimizer"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["optimizer = optim.Adam(model2.parameters(), lr = 0.1)  #model.parameters() takes our model parameters created in dataset"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["LOSS_ADAM = []"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def train_model_ADAM(iter):\n", "    for epoch in range(iter):\n", "        for x,y in trainloader:\n", "            \n", "            yhat = model2(x) #Predict yhat using initialized parameters\n", "            \n", "            loss = criterion(yhat, y) #Calculate the loss MSE \n", "            \n", "            get_surface.set_para_loss(model2, loss.tolist()) #Plot  \n", "            \n", "            #store the loss in the list LOSS_BGD\n", "            LOSS_ADAM.append(loss) #Add the loss to the list LOSS_BGD\n", "            \n", "            optimizer.zero_grad() #Zeros the gradient because otherwise pytorch accumulates it\n", "            \n", "            loss.backward() \n", "            optimizer.step() #Updates parameters\n", "            \n", "            get_surface.plot_ps()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["rain model with lr = 0.1"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_model_ADAM(5)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ets compare the models"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.plot(LOSS_BGD,label = \" Batch Gradient Descent with lr 0.01\")\n", "plt.plot(LOSS_BGD1, label = \" Batch Gradient Descent with lr 0.1\", linestyle='dashed')\n", "plt.plot(LOSS_ADAM, label = \" Batch Gradient Descent with Adam\", linestyle='dotted')\n", "plt.xlabel('epoch')\n", "plt.ylabel('Cost/ total loss')\n", "plt.legend()\n", "plt.show()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}