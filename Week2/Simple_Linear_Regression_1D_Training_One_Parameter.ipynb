{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "Linear Regression 1D: Training One Parameter<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import torch\n", "import numpy as np\n", "import matplotlib.pyplot as plt"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ets use this class for plotting and visualizing the parameter training"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class plot_diagram():\n", "    \n", "    # Constructor\n", "    def __init__(self, X, Y, w, stop, go = False):\n", "        start = w.data\n", "        self.error = []\n", "        self.parameter = []\n", "        self.X = X.numpy()\n", "        self.Y = Y.numpy()\n", "        self.parameter_values = torch.arange(start, stop)\n", "        self.Loss_function = [criterion(forward(X), Y) for w.data in self.parameter_values] \n", "        w.data = start\n", "        \n", "    # Executor\n", "    def __call__(self, Yhat, w, error, n):\n", "        self.error.append(error)\n", "        self.parameter.append(w.data)\n", "        plt.subplot(212)\n", "        plt.plot(self.X, Yhat.detach().numpy())\n", "        plt.plot(self.X, self.Y,'ro')\n", "        plt.xlabel(\"A\")\n", "        plt.ylim(-20, 20)\n", "        plt.subplot(211)\n", "        plt.title(\"Data Space (top) Estimated Line (bottom) Iteration \" + str(n))\n", "        plt.plot(self.parameter_values.numpy(), self.Loss_function)   \n", "        plt.plot(self.parameter, self.error, 'ro')\n", "        plt.xlabel(\"B\")\n", "        plt.figure()\n", "    \n", "    # Destructor\n", "    def __del__(self):\n", "        plt.close('all')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ets generate some values that create a line with a slope of -3"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X = torch.arange(-3, 3, 0.1).view(-1, 1) #View changes the shape of the tensor\n", "f = -3 * X #Function of the line"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ets plot the line"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.plot(X.numpy(), f.numpy(), label = 'f') #We need to convert tensor to numpy\n", "plt.xlabel('x')\n", "plt.ylabel('y')\n", "plt.legend()\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ets add noise to the data to simulate 'real data'. We use torch.randn to generate Gaussian noise."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["Y = f + 0.1 * torch.randn(X.size()) #The noise must be the same size as X"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ets plot Y"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.plot(X.numpy(), Y.numpy(), label = 'Y') #We need to convert tensor to numpy\n", "plt.xlabel('x')\n", "plt.ylabel('y')\n", "plt.legend()\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["reate the model and cost function(total loss)<br>\n", "reate a forward function for prediction"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def forward(x):\n", "    return w * x"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ean Squared Error function for evaluating the result"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def criterion(yhat, y):\n", "    return torch.mean((yhat - y)**2)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["reate a learning rate"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["lr = 0.1"]}, {"cell_type": "markdown", "metadata": {}, "source": ["reate an empty list to append loss results for each iteration"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["LOSS = []"]}, {"cell_type": "markdown", "metadata": {}, "source": ["e create a parameter w with requires_grad = True to indicate that torch must learn it"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["w = torch.tensor(-10.0, requires_grad = True) #Initialize w as -10.0"]}, {"cell_type": "markdown", "metadata": {}, "source": ["reate a plot diagram object to visualize the data and the parameter for each iteration"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["gradient_plot = plot_diagram(X, Y, w, stop = 5)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["reating a function to train the model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def train_model(iter):\n", "    for epoch in range (iter):\n", "        \n", "        #Prediction Yhat using forward function\n", "        Yhat = forward(X)\n", "        \n", "        #loss calculation using criterion loss function on Yhat, Y\n", "        loss = criterion(Yhat,Y)\n", "        \n", "        #Plotting diagram for visualization\n", "        gradient_plot(Yhat, w, loss.item(), epoch)\n", "        \n", "        #Appending Loss to LOSS list\n", "        LOSS.append(loss.item())\n", "        \n", "        #Compute the gradient of the loss wrt all parameters\n", "        loss.backward()\n", "        \n", "        #Update parameters\n", "        w.data = w.data - lr * w.grad.data\n", "        \n", "        #Zero the gradients before running the backward pass\n", "        w.grad.data.zero_()\n", "        \n", "#Lets train the model for 4 iterations\n", "train_model(4)        "]}, {"cell_type": "markdown", "metadata": {}, "source": ["lotting the list LOSS (loss per iteration)        "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.plot(LOSS)\n", "plt.tight_layout()\n", "plt.xlabel(\"Epoch/Iterations\")\n", "plt.ylabel(\"Cost\")        \n", "    \n", "    \n", "#Lets try a new parameter w\n", "w = torch.tensor(-15.0, requires_grad=True) #Initialize w as -15.0"]}, {"cell_type": "markdown", "metadata": {}, "source": ["reate an empty list to store the loss"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["LOSS2 = []\n", "gradient_plot1 = plot_diagram(X, Y, w, stop = 15)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def my_train_model(iter):\n", "    for epoch in range (iter):\n", "        \n", "        #Prediction Yhat using forward function\n", "        Yhat = forward(X)\n", "        \n", "        #loss calculation using criterion loss function on Yhat, Y\n", "        loss = criterion(Yhat,Y)\n", "        \n", "        #Plotting diagram for visualization\n", "        gradient_plot1(Yhat, w, loss.item(), epoch)\n", "        \n", "        #Appending Loss to LOSS list\n", "        LOSS2.append(loss.item())\n", "        \n", "        #Compute the gradient of the loss wrt all parameters\n", "        loss.backward()\n", "        \n", "        #Update parameters\n", "        w.data = w.data - lr * w.grad.data\n", "        \n", "        #Zero the gradients before running the backward pass\n", "        w.grad.data.zero_()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["my_train_model(4)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.plot(LOSS, label = \"LOSS\")\n", "plt.plot(LOSS2, label = \"LOSS2\")\n", "plt.tight_layout()\n", "plt.xlabel(\"Epoch/Iterations\")\n", "plt.ylabel(\"Cost\")\n", "plt.legend()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["e notice that the parameter value is sensitive to initialization."]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}