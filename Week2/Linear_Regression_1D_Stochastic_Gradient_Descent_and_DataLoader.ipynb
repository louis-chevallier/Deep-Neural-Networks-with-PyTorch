{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "Linear Regression 1D: Prediction Stochastic Gradient Descent (SGD) and the DataLoader<br>\n", " <br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import torch\n", "import matplotlib.pyplot as plt\n", "import numpy as np\n", "from mpl_toolkits import mplot3d"]}, {"cell_type": "markdown", "metadata": {}, "source": ["dd a class plot_error_surfaces to visualize the data space and parameters."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class plot_error_surfaces(object):\n", "    \n", "    # Constructor\n", "    def __init__(self, w_range, b_range, X, Y, n_samples = 30, go = True):\n", "        W = np.linspace(-w_range, w_range, n_samples)\n", "        B = np.linspace(-b_range, b_range, n_samples)\n", "        w, b = np.meshgrid(W, B)    \n", "        Z = np.zeros((30, 30))\n", "        count1 = 0\n", "        self.y = Y.numpy()\n", "        self.x = X.numpy()\n", "        for w1, b1 in zip(w, b):\n", "            count2 = 0\n", "            for w2, b2 in zip(w1, b1):\n", "                Z[count1, count2] = np.mean((self.y - w2 * self.x + b2) ** 2)\n", "                count2 += 1\n", "            count1 += 1\n", "        self.Z = Z\n", "        self.w = w\n", "        self.b = b\n", "        self.W = []\n", "        self.B = []\n", "        self.LOSS = []\n", "        self.n = 0\n", "        if go == True:\n", "            plt.figure()\n", "            plt.figure(figsize = (7.5, 5))\n", "            plt.axes(projection = '3d').plot_surface(self.w, self.b, self.Z, rstride = 1, cstride = 1,cmap = 'viridis', edgecolor = 'none')\n", "            plt.title('Loss Surface')\n", "            plt.xlabel('w')\n", "            plt.ylabel('b')\n", "            plt.show()\n", "            plt.figure()\n", "            plt.title('Loss Surface Contour')\n", "            plt.xlabel('w')\n", "            plt.ylabel('b')\n", "            plt.contour(self.w, self.b, self.Z)\n", "            plt.show()\n", "    \n", "    # Setter\n", "    def set_para_loss(self, W, B, loss):\n", "        self.n = self.n + 1\n", "        self.W.append(W)\n", "        self.B.append(B)\n", "        self.LOSS.append(loss)\n", "    \n", "    # Plot diagram\n", "    def final_plot(self): \n", "        ax = plt.axes(projection = '3d')\n", "        ax.plot_wireframe(self.w, self.b, self.Z)\n", "        ax.scatter(self.W, self.B, self.LOSS, c = 'r', marker = 'x', s = 200, alpha = 1)\n", "        plt.figure()\n", "        plt.contour(self.w, self.b, self.Z)\n", "        plt.scatter(self.W, self.B, c = 'r', marker = 'x')\n", "        plt.xlabel('w')\n", "        plt.ylabel('b')\n", "        plt.show()\n", "    \n", "    # Plot diagram\n", "    def plot_ps(self):\n", "        plt.subplot(121)\n", "        plt.ylim\n", "        plt.plot(self.x, self.y, 'ro', label = \"training points\")\n", "        plt.plot(self.x, self.W[-1] * self.x + self.B[-1], label = \"estimated line\")\n", "        plt.xlabel('x')\n", "        plt.ylabel('y')\n", "        plt.ylim((-10, 15))\n", "        plt.title('Data Space Iteration: ' + str(self.n))\n", "        plt.subplot(122)\n", "        plt.contour(self.w, self.b, self.Z)\n", "        plt.scatter(self.W, self.B, c = 'r', marker = 'x')\n", "        plt.title('Loss Surface Contour Iteration' + str(self.n))\n", "        plt.xlabel('w')\n", "        plt.ylabel('b')\n", "        plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["reating random data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["torch.manual_seed(1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["enerating values"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X = torch.arange(-3, 3, 0.1).view(-1, 1) #X -3 to 3 with 0.1 steps\n", "f = 1 * X - 1\n", "Y = f + 0.1 * torch.randn(X.size()) #Adding random noise "]}, {"cell_type": "markdown", "metadata": {}, "source": ["ets plot Y, X, f"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.plot(X.numpy(), Y.numpy(), 'rx', label = 'y')\n", "plt.plot(X.numpy(), f.numpy(), label = 'f')\n", "plt.xlabel('x')\n", "plt.ylabel('y')\n", "plt.legend()\n", "plt.show()\n", " \n", "# Define the forward function\n", "def forward(x):\n", "    return w * x + b"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Define the MSE Loss function"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def criterion(yhat, y):\n", "    return torch.mean((yhat - y) ** 2) #Mean Squared Error "]}, {"cell_type": "markdown", "metadata": {}, "source": ["e use plot_error_surfaces to visualize"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["get_surface = plot_error_surfaces(15, 13, X, Y, 30)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Define the parameters w, b for y = wx + b"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["w = torch.tensor(-15.0, requires_grad = True) #Requires_grad = true because torch needs to learn it.\n", "b = torch.tensor(-10.0, requires_grad = True) #Requires_grad = true because torch needs to learn it."]}, {"cell_type": "markdown", "metadata": {}, "source": ["efine a learning rate and create an empty list LOSS to store the loss for each iteration"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["lr = 0.1 #Our first choice learning rate\n", "LOSS_BGD = []"]}, {"cell_type": "markdown", "metadata": {}, "source": ["he functipn for training the model. We will use the functions we create in it. <br>\n", "e Will use Batch Gradient Descent"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def train_model(iter):\n", "    \n", "    #Epoch loop\n", "    for epoch in range(iter):\n", "        # make a prediction\n", "        Yhat = forward(X)\n", "        \n", "        # calculate the loss \n", "        loss = criterion(Yhat, Y)\n\n", "        # Section for plotting\n", "        get_surface.set_para_loss(w.data.tolist(), b.data.tolist(), loss.tolist())\n", "        get_surface.plot_ps()\n", "            \n", "        # store the loss in the list LOSS_BGD\n", "        LOSS_BGD.append(loss)\n", "        \n", "        # backward pass: compute gradient of the loss with respect to all the learnable parameters\n", "        loss.backward()\n", "        \n", "        # update parameters slope and bias\n", "        w.data = w.data - lr * w.grad.data\n", "        b.data = b.data - lr * b.grad.data\n", "        \n", "        # zero the gradients before running the backward pass\n", "        w.grad.data.zero_()\n", "        b.grad.data.zero_()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["rain model for 10 iteations"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_model(10)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ets train with Stochastic Gradient Descent"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["get_surface = plot_error_surfaces(15, 13, X, Y, 30, go = False)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["LOSS_SGD = []\n", "w = torch.tensor(-15.0, requires_grad = True)\n", "b = torch.tensor(-10.0, requires_grad = True)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["efining model with Stochastic Gradient Descent"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def train_model_SGD(iter):\n", "    \n", "    #Epoch Loop\n", "    for epoch in range(iter):\n", "        \n", "        #SGD is an approximation of out true total loss/cost, in this line of code we calculate our true loss/cost and store it\n", "        Yhat = forward(X)\n\n", "        #Store the loss \n", "        LOSS_SGD.append(criterion(Yhat, Y).tolist())\n", "        \n", "        for x, y in zip(X, Y):\n", "            \n", "            #make a pridiction\n", "            yhat = forward(x)\n", "        \n", "            #calculate the loss \n", "            loss = criterion(yhat, y)\n\n", "            #Section for plotting\n", "            get_surface.set_para_loss(w.data.tolist(), b.data.tolist(), loss.tolist())\n", "        \n", "            #backward pass: compute gradient of the loss with respect to all the learnable parameters\n", "            loss.backward()\n", "        \n", "            #update parameters slope and bias\n", "            w.data = w.data - lr * w.grad.data\n", "            b.data = b.data - lr * b.grad.data\n\n", "            #zero the gradients before running the backward pass\n", "            w.grad.data.zero_()\n", "            b.grad.data.zero_()\n", "            \n", "        #plot surface and data space after each epoch    \n", "        get_surface.plot_ps()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["un for 10 epochs"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_model_SGD(10)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ets Compare the two models<br>\n", "lot out the LOSS_BGD and LOSS_SGD"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.plot(LOSS_BGD,label = \"Batch Gradient Descent\")\n", "plt.plot(LOSS_SGD,label = \"Stochastic Gradient Descent\")\n", "plt.xlabel('epoch')\n", "plt.ylabel('Cost/ total loss')\n", "plt.legend()\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "SGD with Dataset DataLoader<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from torch.utils.data import Dataset, DataLoader"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ataset Creation Class"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class Data(Dataset):\n", "    #Constructor\n", "    def __init__(self):\n", "        self.x = torch.arange(-3, 3, 0.1).view(-1, 1)\n", "        self.y = 1 * self.x - 1\n", "        self.len = self.x.shape[0]\n", "        \n", "    #Getter\n", "    def __getitem__(self,index):    \n", "        return self.x[index], self.y[index]\n", "    \n", "    #Return the length\n", "    def __len__(self):\n", "        return self.len"]}, {"cell_type": "markdown", "metadata": {}, "source": ["reate a Dataset object"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["dataset = Data()\n", "print(\"The length of dataset: \", len(dataset)) #Using the len method in the Data class"]}, {"cell_type": "markdown", "metadata": {}, "source": ["e can obtain value in the dataset with index numbers using the Getitem method in the class"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["x, y = dataset[0]\n", "print(x,\" , \", y)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["licing the first 3 points"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["x, y = dataset[0:3]\n", "print(\"The first 3 x: \", x)\n", "print(\"The first 3 y: \", y)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["get_surface = plot_error_surfaces(15, 13, X, Y, 30, go = False)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ets create the DataLoader object"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["trainloader = DataLoader(dataset = dataset, batch_size = 1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["w = torch.tensor(-15.0,requires_grad=True)\n", "b = torch.tensor(-10.0,requires_grad=True)\n", "LOSS_Loader = []"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ets define our new function<br>\n", "rain_model_DataLoader"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def train_model_DataLoader(epochs):\n", "    \n", "    #Epoch Loop\n", "    for epoch in range(epochs):\n", "        \n", "        #SGD is an approximation of out true total loss/cost, in this line of code we calculate our true loss/cost and store it\n", "        Yhat = forward(X)\n", "        \n", "        #store the loss \n", "        LOSS_Loader.append(criterion(Yhat, Y).tolist())\n", "        \n", "        for x, y in trainloader:\n", "            \n", "            #make a prediction\n", "            yhat = forward(x)\n", "            \n", "            #calculate the loss\n", "            loss = criterion(yhat, y)\n", "            \n", "            #Section for plotting\n", "            get_surface.set_para_loss(w.data.tolist(), b.data.tolist(), loss.tolist())\n", "            \n", "            #Backward pass: compute gradient of the loss with respect to all the learnable parameters\n", "            loss.backward()\n", "            \n", "            #Update parameters slope\n", "            w.data = w.data - lr * w.grad.data\n", "            b.data = b.data - lr* b.grad.data\n", "            \n", "            #Clear gradients \n", "            w.grad.data.zero_()\n", "            b.grad.data.zero_()\n", "            \n", "        #plot surface and data space after each epoch    \n", "        get_surface.plot_ps()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["un for 10 epochs"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_model_DataLoader(10)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Plot the LOSS_BGD and LOSS_Loader"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.plot(LOSS_BGD,label=\"Batch Gradient Descent\")\n", "plt.plot(LOSS_Loader,label=\"Stochastic Gradient Descent with DataLoader\")\n", "plt.xlabel('epoch')\n", "plt.ylabel('Cost/ total loss')\n", "plt.legend()\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ets try another one with SGD and DataLoader"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["LOSS1 = []\n", "w = torch.tensor(-12.0, requires_grad = True)\n", "b = torch.tensor(-10.0, requires_grad = True)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def train_model_DataLoader1(epochs):\n", "    \n", "    #Epoch Loop\n", "    for epoch in range(epochs):\n", "        \n", "        #SGD is an approximation of out true total loss/cost, in this line of code we calculate our true loss/cost and store it\n", "        Yhat = forward(X)\n", "        \n", "        #store the loss \n", "        LOSS1.append(criterion(Yhat, Y).tolist())\n", "        \n", "        for x, y in trainloader:\n", "            \n", "            #make a prediction\n", "            yhat = forward(x)\n", "            \n", "            #calculate the loss\n", "            loss = criterion(yhat, y)\n", "            \n", "            #Section for plotting\n", "            get_surface.set_para_loss(w.data.tolist(), b.data.tolist(), loss.tolist())\n", "            \n", "            #Backward pass: compute gradient of the loss with respect to all the learnable parameters\n", "            loss.backward()\n", "            \n", "            #Update parameters slope\n", "            w.data = w.data - lr * w.grad.data\n", "            b.data = b.data - lr* b.grad.data\n", "            \n", "            #Clear gradients \n", "            w.grad.data.zero_()\n", "            b.grad.data.zero_()\n", "            \n", "        #plot surface and data space after each epoch    \n", "        get_surface.plot_ps()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["un for 10 epochs"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_model_DataLoader1(10)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.plot(LOSS1,label = \"Stochastic Gradient Descent w/ DataLoader\")\n", "plt.plot(LOSS_BGD, color = 'orange', linestyle = 'dashed', label = \"Batch Gradient Descent\")\n", "plt.xlabel('iteration')\n", "plt.ylabel('Cost/ total loss')\n", "plt.legend()\n", "plt.show()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}