{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "Convolution 2D with Multiple Outputs<br>\n", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[1] Imports"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import torch \n", "import torch.nn as nn\n", "import matplotlib.pyplot as plt\n", "import numpy as np"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[2] Conv 2D"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Conv2D with in_channels = 1 and out_channels = 3 and Kernel = 3,3. Stride default(1,1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["conv1 = nn.Conv2d(in_channels=1, out_channels=3, kernel_size=3)\n", "conv1"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Creating tensors for kernel weights"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["Gx = torch.tensor([[1.0,0,-1.0],[2.0,0,-2.0],[1.0,0.0,-1.0]])\n", "Gy = torch.tensor([[1.0,2.0,1.0],[0.0,0.0,0.0],[-1.0,-2.0,-1.0]])\n", "Gz = torch.ones(3,3)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Manual initialization of kernel weights and bias"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["conv1.state_dict() # dictionary containing keys (weights, bias)\n", "conv1.state_dict()['weight'][0][0] = Gx \n", "conv1.state_dict()['weight'][1][0] = Gy\n", "conv1.state_dict()['weight'][2][0] = Gz\n", "conv1.state_dict()['weight']\n", "conv1.state_dict()['bias'][:] = torch.tensor([0.0,0.0,0.0])\n", "conv1.state_dict()['bias']"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Showing kernels weights"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for x in conv1.state_dict()['weight']:\n", "    print(x)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Showing bias in kernels"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for x in conv1.state_dict()['bias']:\n", "    print(x)\n", "    \n", "# In[3] Create Data/Image"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["image = torch.zeros(1, 1, 5, 5) # Vertical white block in the middle\n", "image[0,0,:,2] = 1\n", "image "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["image1 = torch.zeros(1, 1, 5, 5) # Horizontal white block in the middle\n", "image1[0, 0, 2, :] = 1\n", "image1"]}, {"cell_type": "markdown", "metadata": {}, "source": ["plot image"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.imshow(image[0, 0, :, :].numpy(), cmap = 'gray')\n", "plt.colorbar()\n", "plt.show"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.imshow(image1[0, 0, :, :].numpy(), cmap = 'gray')\n", "plt.colorbar()\n", "plt.show"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[4] Perform convolution and Plot"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["out = conv1(image)\n", "out1 = conv1(image1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["out.shape\n", "out1.shape"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Print channels as tensors/image and plot for image"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for channel, image in enumerate(out[0]):\n", "    plt.imshow(image.detach().numpy(), cmap = 'gray')\n", "    print(image)\n", "    plt.title(\"channel {}\".format(channel))\n", "    plt.colorbar()\n", "    plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Print channels as tensors/image and plot for image1"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for channel, image1 in enumerate(out1[0]):\n", "    plt.imshow(image1.detach().numpy(), cmap = 'gray')\n", "    print(image1)\n", "    plt.title(\"channel {}\".format(channel))\n", "    plt.colorbar()\n", "    plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["It can be seen that different kernels can be used to detect various features in an image. "]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[4] Create Data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["image2 = torch.zeros(1,2,5,5)\n", "image2[0,0,2,:] = -2\n", "image2[0,1,2,:] = 1\n", "image2\n", "image2.shape"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for channel,image in enumerate(image2[0]):\n", "    plt.imshow(image.detach().numpy(), cmap = 'gray')\n", "    print(image)\n", "    plt.title(\"channel {}\".format(channel))\n", "    plt.colorbar()\n", "    plt.show()\n", "    "]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[5] Create Conv2D object"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Conv2D object with 2 inputs and 1 ouput, kernel (3,3)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["conv3 = nn.Conv2d(in_channels=2, out_channels=1, kernel_size=1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Manual kernel initialization"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["Gx1 = torch.tensor([[0.0,0.0,0.0],[0,1.0,0],[0.0,0.0,0.0]])\n", "conv3.state_dict()['weight'][0][0] = 1*Gx1\n", "conv3.state_dict()['weight'][0][1] = -2*Gx1\n", "conv3.state_dict()['bias'][:] = torch.tensor([0.0])\n", "conv3.state_dict()\n", "conv3.state_dict()['weight']"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[6] Perform convolution and Plot"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["out3 = conv3(image2)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Print channels as tensors/image and plot for image1"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for channel, image2 in enumerate(out3[0]):\n", "    plt.imshow(image2.detach().numpy(), cmap = 'gray')\n", "    print(image1)\n", "    plt.title(\"channel {}\".format(channel))\n", "    plt.colorbar()\n", "    plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[7] Create Conv2D and Data with multiple inputs and outputs"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Create conv2D with 2 in_channels and 3 out_channels, kernel_size (3,3)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["conv4 = nn.Conv2d(in_channels=2, out_channels=3, kernel_size=3)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Manual weight and bias initialization"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["conv4.state_dict()['weight'][0][0] = torch.tensor([[0.0,0.0,0.0],[0,0.5,0],[0.0,0.0,0.0]])\n", "conv4.state_dict()['weight'][0][1] = torch.tensor([[0.0,0.0,0.0],[0,0.5,0],[0.0,0.0,0.0]])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["conv4.state_dict()['weight'][1][0] = torch.tensor([[0.0,0.0,0.0],[0,1,0],[0.0,0.0,0.0]])\n", "conv4.state_dict()['weight'][1][1] = torch.tensor([[0.0,0.0,0.0],[0,-1,0],[0.0,0.0,0.0]])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["conv4.state_dict()['weight'][2][0] = torch.tensor([[1.0,0,-1.0],[2.0,0,-2.0],[1.0,0.0,-1.0]])\n", "conv4.state_dict()['weight'][2][1] = torch.tensor([[1.0,2.0,1.0],[0.0,0.0,0.0],[-1.0,-2.0,-1.0]])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["conv4.state_dict()['bias'][:]=torch.tensor([0.0,0.0,0.0])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["image4 = torch.zeros(1,2,5,5)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["image4[0][0] = torch.ones(5,5)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["image4[0][1][2][2] = 1"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for channel, image in enumerate(image4[0]):\n", "    plt.imshow(image.detach().numpy(), cmap = 'gray' )\n", "    print(image)\n", "    plt.title(\"channel {}\".format(channel))\n", "    plt.colorbar()\n", "    plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Apply conv to image"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["z = conv4(image4)\n", "z"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}