{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "Convolutional Neural Network with Small Images<br>\n", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[1] Imports"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import torch\n", "import torch.nn as nn\n", "import torchvision.transforms as transforms\n", "import torchvision.datasets as dsets\n", "from torch.utils.data import DataLoader\n", "import matplotlib.pyplot as plt\n", "import numpy as np"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[2] Plot function"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Define the function for plotting the channels"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def show_data(data_sample):\n", "    plt.imshow(data_sample[0].numpy().reshape(IMAGE_SIZE, IMAGE_SIZE), cmap='gray')\n", "    plt.title('y = ' + str(data_sample[1].item()))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[3] Create Data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["IMAGE_SIZE = 16"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Create a transform to resize image and convert to tensor"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["transformation = transforms.Compose([transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)), transforms.ToTensor()])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Create Dataset from MNIST and apply composed transformation"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_dataset = dsets.MNIST(root='./data', train=True, download=True, transform=transformation)\n", "validation_dataset = dsets.MNIST(root='./data', train=False, download=True, transform=transformation)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Check Data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_dataset[0][1]  # Label - int object\n", "train_dataset[0][0]\n", "train_dataset[0][0].size()\n", "train_dataset[0][0].type()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_dataset[1][1]\n", "train_dataset[1][0]\n", "train_dataset[1][0].size()\n", "train_dataset[1][0].type()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Lets plot some images.<br>\n", "We need to squeeze the (1, 16, 16) to (16, 16) and convert to numpy array<br>\n", "We can also use reshape(16, 16)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.imshow(train_dataset[1][0].squeeze().numpy())\n", "plt.imshow(train_dataset[5][0].reshape(16, 16).numpy())\n", "# Plot in gray scale\n", "plt.imshow(train_dataset[5][0].reshape(16, 16).numpy(), cmap='gray')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We can use show_data function"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["show_data(train_dataset[1][0])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[4] Create CNN Class"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class CNN(nn.Module):\n\n", "    # Constructor\n", "    def __init__(self, out_1=16, out_2=32):\n", "        super().__init__()\n", "        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=out_1, kernel_size=5, padding=2)\n", "        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n", "        self.ELU = nn.ELU()\n", "        self.cnn2 = nn.Conv2d(in_channels=out_1, out_channels=out_2, kernel_size=5, padding=2)\n", "        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n", "        self.fc1 = nn.Linear(out_2*4*4, 10)\n\n", "    # Prediction\n", "    def forward(self, x):\n", "        x = self.cnn1(x)\n", "        x = self.ELU(x)\n", "        x = self.maxpool1(x)\n", "        x = self.cnn2(x)\n", "        x = self.ELU(x)\n", "        x = self.maxpool2(x)\n", "        x = x.view(x.size(0), -1)\n", "        x = self.fc1(x)\n", "        return x\n\n", "    # Outputs in each step\n", "    def activations(self, x):\n", "        # This part is for visualization purposes\n", "        z1 = self.cnn1(x)\n", "        a1 = self.ELU(z1)\n", "        out = self.maxpool1(a1)\n", "        z2 = self.cnn2(out)\n", "        a2 = self.ELU(z2)\n", "        out1 = self.maxpool2(a2)\n", "        out2 = out1.view(out1.size(0), -1)\n", "        return z1, a1, out, z2, a2, out1, out2"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[5] Train loop and training"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def train_model(model, train_loader, validation_loader, optimizer, n_epochs=4):\n\n", "    # Global variable\n", "    N_test = len(validation_dataset)\n", "    accuracy_list = []\n", "    loss_list = []\n", "    for epoch in range(n_epochs):\n", "        for x, y in train_loader:\n", "            model.train()\n", "            optimizer.zero_grad()\n", "            z = model(x)\n", "            loss = criterion(z, y)\n", "            loss.backward()\n", "            optimizer.step()\n", "            loss_list.append(loss.data)\n", "        correct = 0\n", "        # Perform a prediction on the validation data\n", "        for x_test, y_test in validation_loader:\n", "            model.eval()\n", "            z = model(x_test)\n", "            _, yhat = torch.max(z.data, 1)\n", "            correct += (yhat == y_test).sum().item()\n", "        accuracy = correct / N_test\n", "        accuracy_list.append(accuracy)\n", "    return accuracy_list, loss_list"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[6] Batch Normalization CNN class"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class CNN_BatchNorm(nn.Module):\n", "    # Constructor\n", "    def __init__(self, out_1=16, out_2=32):\n", "        super().__init__()\n", "        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=out_1, kernel_size=5, padding=2)\n", "        self.conv1_bn = nn.BatchNorm2d(out_1)  # To normalize conv2D, we need BatchNorm2D\n", "        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n", "        self.ELU = nn.ELU()\n", "        self.cnn2 = nn.Conv2d(in_channels=out_1, out_channels=out_2, kernel_size=5, padding=2)\n", "        self.conv2_bn = nn.BatchNorm2d(out_2)\n", "        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n", "        self.fc1 = nn.Linear(out_2*4*4, 10)\n", "        self.bn_fc1 = nn.BatchNorm1d(10)  # To normalize linear layer, BatchNorm1D must be used\n\n", "    # Prediction\n", "    def forward(self, x):\n", "        x = self.cnn1(x)\n", "        x = self.conv1_bn(x)\n", "        x = self.ELU(x)\n", "        x = self.maxpool1(x)\n", "        x = self.cnn2(x)\n", "        x = self.conv2_bn(x)\n", "        x = self.ELU(x)\n", "        x = self.maxpool2(x)\n", "        x = x.view(x.size(0), -1)\n", "        x = self.fc1(x)\n", "        x = self.bn_fc1(x)\n", "        return x"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[7] Initialize, create loss function, optimizer and data loaders"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Create model object from CNN class"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model = CNN(16, 32)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Optimizer"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Loss function criterion"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["criterion = nn.CrossEntropyLoss()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["train and val loader"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_loader = DataLoader(dataset=train_dataset, batch_size=100)\n", "validation_loader = DataLoader(dataset=validation_dataset, batch_size=5000)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["accuracy_list_normal, loss_list_normal = train_model(model=model,\n", "                                                     n_epochs=10, train_loader=train_loader, validation_loader=validation_loader,\n", "                                                     optimizer=optimizer)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Create model_BatchNorm object from CNN_BatchNorm class"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model_BatchNorm = CNN_BatchNorm(16, 32)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Optimizer"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["optimizer_BatchNorm = torch.optim.Adam(model_BatchNorm.parameters(), lr=0.01)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["accuracy_list_batch, loss_list_batch = train_model(model=model_BatchNorm,\n", "                                                   n_epochs=10, train_loader=train_loader, validation_loader=validation_loader,\n", "                                                   optimizer=optimizer_BatchNorm)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[8] Analyze Results and Compare"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Plot the loss and accuracy"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.plot(loss_list_normal, 'b', label='loss normal cnn')\n", "plt.plot(loss_list_batch, 'r', label='loss batch cnn')\n", "plt.xlabel('iteration')\n", "plt.title(\"loss\")\n", "plt.legend()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.plot(accuracy_list_normal, 'b', label='normal CNN')\n", "plt.plot(accuracy_list_batch, 'r', label='CNN with Batch Norm')\n", "plt.xlabel('Epoch')\n", "plt.title(\"Accuracy \")\n", "plt.legend()\n", "plt.show()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}