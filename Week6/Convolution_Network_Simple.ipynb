{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "Convolution Neural Network Simple Example<br>\n", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[1] Imports"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import torch \n", "import torch.nn as nn\n", "import torchvision.transforms as transforms\n", "import torchvision.datasets as dsets\n", "from torch.utils.data import Dataset, DataLoader\n", "import matplotlib.pylab as plt\n", "import numpy as np\n", "import pandas as pd\n", "torch.manual_seed(0)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[2] Plotting"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Plot function"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def plot_channels(W):\n", "    #number of output channels \n", "    n_out = W.shape[0]\n", "    #number of input channels \n", "    n_in = W.shape[1]\n", "    w_min = W.min().item()\n", "    w_max = W.max().item()\n", "    fig, axes = plt.subplots(n_out, n_in)\n", "    fig.subplots_adjust(hspace=0.1)\n", "    out_index = 0\n", "    in_index = 0\n", "    #plot outputs as rows inputs as columns \n", "    for ax in axes.flat:\n", "    \n", "        if in_index>n_in-1:\n", "            out_index=out_index+1\n", "            in_index=0\n", "              \n", "        ax.imshow(W[out_index,in_index,:,:], vmin = w_min, vmax = w_max, cmap = 'seismic')\n", "        ax.set_yticklabels([])\n", "        ax.set_xticklabels([])\n", "        in_index = in_index+1\n", "    plt.show()\n", "    \n", "# Plot data sample"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def show_data(dataset, sample):\n", "    plt.imshow(dataset.x[sample, 0, :, :].numpy(), cmap = 'gray')\n", "    plt.title('y= '+str(dataset.y[sample].item()))\n", "    plt.show()\n", "  \n", "    \n", "# In[3] Create Data/Images"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class Data(Dataset):\n", "    \n", "    def __init__(self, N_images=100, offset=0, p=0.9, train=False):\n", "        \"\"\"\n", "        p: portability that pixel is white\n", "        N_images: number of images \n", "        offset: set a random vertical and horizontal offset images by a sample (should be less than 3)\n", "        \n", "        \"\"\"\n", "       \n", "        if train==True:\n", "            np.random.seed(0)  \n", "        \n", "        # Make images multiple of 3 \n", "        N_images = 2 * (N_images//2)\n", "        images = np.zeros((N_images, 1, 11, 11))\n", "        start1 = 3\n", "        start2 = 1\n", "        self.y = torch.zeros(N_images).type(torch.long)\n", "        for n in range(N_images):\n", "            if offset>0:\n", "        \n", "                low = int(np.random.randint(low = start1, high = start1+offset, size=1))\n", "                high = int(np.random.randint(low = start2, high = start2+offset, size=1))\n", "            else:\n", "                low = 4\n", "                high = 1\n", "        \n", "            if n <= N_images//2:\n", "                self.y[n] = 0\n", "                images[n, 0, high:high+9, low:low+3] = np.random.binomial(1, p, (9,3))\n", "            elif  n > N_images//2:\n", "                self.y[n] = 1\n", "                images[n, 0, low:low+3, high:high+9] = np.random.binomial(1, p, (3,9))\n", "           \n", "        \n", "        \n", "        self.x = torch.from_numpy(images).type(torch.FloatTensor)\n", "        self.len = self.x.shape[0]\n", "        del(images)\n", "        np.random.seed(0)\n", "    \n", "    \n", "    def __getitem__(self, index):      \n", "        return self.x[index], self.y[index]\n", "    \n", "    \n", "    def __len__(self):\n", "        return self.len"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[4] Plot activations of the Convolutional Layer"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def plot_activations(A, number_rows = 1, name = \"\"):\n", "    A = A[0,:,:,:].detach().numpy()\n", "    n_activations = A.shape[0]\n", "    \n", "    \n", "    print(n_activations)\n", "    A_min = A.min().item()\n", "    A_max = A.max().item()\n", "    if n_activations == 1:\n\n", "        # Plot the image.\n", "        plt.imshow(A[0,:], vmin = A_min, vmax = A_max, cmap = 'seismic')\n", "    else:\n", "        fig, axes = plt.subplots(number_rows, n_activations//number_rows)\n", "        fig.subplots_adjust(hspace = 0.4)\n", "        for i,ax in enumerate(axes.flat):\n", "            if i< n_activations:\n", "                # Set the label for the sub-plot.\n", "                ax.set_xlabel( \"activation:{0}\".format(i+1))\n", "                # Plot the image.\n", "                ax.imshow(A[i,:], vmin = A_min, vmax = A_max, cmap = 'seismic')\n", "                ax.set_xticks([])\n", "                ax.set_yticks([])\n", "    plt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def conv_output_shape(h_w, kernel_size=1, stride=1, padding=0, dilation=1):\n", "    \n", "    #by Duane Nielsen\n", "    from math import floor\n", "    \n", "    if type(kernel_size) is not tuple:\n", "        \n", "        kernel_size = (kernel_size, kernel_size)\n", "    h = floor( ((h_w[0] + (2 * padding) - ( dilation * (kernel_size[0] - 1) ) - 1 )/ stride) + 1)\n", "    w = floor( ((h_w[1] + (2 * padding) - ( dilation * (kernel_size[1] - 1) ) - 1 )/ stride) + 1)\n", "    \n", "    return h, w"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[4] Create Datasets"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["N_images = 10000\n", "train_dataset = Data(N_images=N_images)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["validation_dataset = Data(N_images=1000,train=False)\n", "validation_dataset"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["show_data(train_dataset, 0)   "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["show_data(train_dataset, N_images//2+2)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["out = conv_output_shape((11, 11), kernel_size=2, stride=1, padding=0, dilation=1)\n", "print(out)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["out1 = conv_output_shape(out, kernel_size=2, stride=1, padding=0, dilation=1)\n", "print(out1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["out2 = conv_output_shape(out1, kernel_size=2, stride=1, padding=0, dilation=1)\n", "print(out2)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["out3 = conv_output_shape(out2, kernel_size=2, stride=1, padding=0, dilation=1)\n", "print(out3)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[5] Create Conv2D Class"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class CNN(nn.Module):\n", "    def __init__(self,out_1=2,out_2=1):\n", "        super().__init__()\n", "        # First conv layer and maxpool\n", "        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=out_1, kernel_size=2, padding=0)\n", "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=1)\n", "        \n", "        # Second conv layer and maxpool\n", "        self.cnn2 = nn.Conv2d(in_channels=out_1, out_channels=out_2, kernel_size=2, stride=1, padding=0)\n", "        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=1)\n", "        \n", "        # Fully connected layer/ Linear layer\n", "        self.fc1 = nn.Linear(out_2*7*7, 2)\n", "     \n", "        \n", "    def forward(self,x):\n", "        x = self.cnn1(x)\n", "        x = torch.relu(x)\n", "        x = self.maxpool1(x)\n", "        x = self.cnn2(x)\n", "        x = torch.relu(x)\n", "        x = self.maxpool2(x)\n", "        x = x.view(x.size(0), -1) #Flattening maxpool2 output to a column\n", "        x = self.fc1(x)\n", "        return x\n", "    \n", "    \n", "    def activations(self,x):\n", "        # These are just for visualization\n", "        z1 = self.cnn1(x)\n", "        a1 = torch.relu(z1)\n", "        out = self.maxpool1(a1)\n", "        \n", "        z2 = self.cnn2(out)\n", "        a2 = torch.relu(z2)\n", "        out = self.maxpool2(a2)\n", "        out = out.view(out.size(0), -1)\n", "        return z1, a1, z2, a2, out"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[6] Create model, criterion loss function, optimizer, val and train loaders"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model = CNN(2, 1)\n", "model"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Plot the weights"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plot_channels(model.state_dict()['cnn1.weight'])\n", "plot_channels(model.state_dict()['cnn2.weight'])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Loss function"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["criterion = nn.CrossEntropyLoss()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Optimizer"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Train and Val loaders"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_loader = DataLoader(dataset=train_dataset, batch_size=10)\n", "validation_loader = DataLoader(dataset=validation_dataset, batch_size=20)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[7] Training loop"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["n_epochs = 10\n", "cost_list = []\n", "accuracy_list = []\n", "N_test = len(validation_dataset)\n", "cost = 0"]}, {"cell_type": "markdown", "metadata": {}, "source": ["_epochs"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for epoch in range(n_epochs):\n", "   \n", "    cost=0    \n", "    for x, y in train_loader:\n", "        \n", "        # Clear gradient \n", "        optimizer.zero_grad()\n", "        \n", "        # Prediction \n", "        z = model(x)\n", "        \n", "        # Calculate loss \n", "        loss = criterion(z,y)\n", "        \n", "        # Calculate gradients of parameters \n", "        loss.backward()\n", "        \n", "        # Update parameters \n", "        optimizer.step()\n", "        \n", "        cost += loss.item()\n", "        \n", "    cost_list.append(cost) # Add cost to cost_list\n", "        \n", "        \n", "    correct = 0\n", "    \n", "    # Prediction on the validation data  \n", "    \n", "    for x_test, y_test in validation_loader:\n", "        \n", "        # Prediction\n", "        z = model(x_test)\n", "        \n", "        # Take max value as prediction\n", "        _,yhat = torch.max(z.data,1)\n\n", "        # Sum the number of correct predictions (yhat==y_test)\n", "        correct += (yhat==y_test).sum().item()\n", "        \n", "    accuracy = correct/N_test\n", "    accuracy_list.append(accuracy)\n", "    \n", "    \n", "# In[8] Analyze results and plot data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig, ax1 = plt.subplots()\n", "color = 'tab:red'\n", "ax1.plot(cost_list, color=color)\n", "ax1.set_xlabel('epoch', color=color)\n", "ax1.set_ylabel('total loss', color=color)\n", "ax1.tick_params(axis='y', color=color)\n", "    \n", "ax2 = ax1.twinx()  \n", "color = 'tab:blue'\n", "ax2.set_ylabel('accuracy', color=color)  \n", "ax2.plot( accuracy_list, color=color)\n", "ax2.tick_params(axis='y', labelcolor=color)\n", "fig.tight_layout()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Lets check the weights for each conv layer"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model.state_dict()['cnn1.weight']\n", "plot_channels(model.state_dict()['cnn1.weight'])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model.state_dict()['cnn1.weight']\n", "plot_channels(model.state_dict()['cnn2.weight'])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["show_data(train_dataset,N_images//2+2)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["out = model.activations(train_dataset[N_images//2+2][0].view(1, 1, 11, 11))\n", "out = model.activations(train_dataset[0][0].view(1, 1, 11, 11))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plot_activations(out[0], number_rows=1, name = \" feature map\")\n", "plt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plot_activations(out[2], number_rows=1, name = \"2nd feature map\")\n", "plt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plot_activations(out[3], number_rows=1, name = \"first feature map\")\n", "plt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["out1 = out[4][0].detach().numpy()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["out0 = model.activations(train_dataset[100][0].view(1,1,11,11))[4][0].detach().numpy()\n", "out0"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.subplot(2, 1, 1)\n", "plt.plot( out1, 'b')\n", "plt.title('Flatted Activation Values')\n", "plt.ylabel('Activation')\n", "plt.xlabel('index')\n", "plt.subplot(2, 1, 2)\n", "plt.plot(out0, 'r')\n", "plt.xlabel('index')\n", "plt.ylabel('Activation')"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}